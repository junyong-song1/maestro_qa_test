#!/usr/bin/env python3
"""
API íŒ¨í„´ ë¶„ì„ ë° ì´ìƒ ê°ì§€ ì‹œìŠ¤í…œ
API í˜¸ì¶œ íŒ¨í„´ í•™ìŠµ ë° ë¹„ì •ìƒ íŒ¨í„´ ê°ì§€
"""

import sqlite3
import json
import logging
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import re

logger = logging.getLogger(__name__)

class APIPatternAnalyzer:
    """API íŒ¨í„´ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, db_path: str = "artifacts/test_log.db"):
        self.db_path = db_path
        self.pattern_cache = {}
        self.anomaly_threshold = 0.1  # 10% ì´ìƒ ì°¨ì´ë‚˜ë©´ ì´ìƒìœ¼ë¡œ íŒë‹¨
        
    def analyze_api_patterns(self, hours: int = 24) -> Dict:
        """API í˜¸ì¶œ íŒ¨í„´ ë¶„ì„"""
        try:
            api_data = self._get_api_data(hours)
            if not api_data:
                return {"status": "no_data", "message": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
            
            # ë‹¤ì–‘í•œ íŒ¨í„´ ë¶„ì„
            patterns = {
                "endpoint_frequency": self._analyze_endpoint_frequency(api_data),
                "method_distribution": self._analyze_method_distribution(api_data),
                "status_code_patterns": self._analyze_status_patterns(api_data),
                "timing_patterns": self._analyze_timing_patterns(api_data),
                "request_sequences": self._analyze_request_sequences(api_data),
                "anomalies": self._detect_anomalies(api_data)
            }
            
            return {
                "status": "success",
                "patterns": patterns,
                "analysis_period": f"ìµœê·¼ {hours}ì‹œê°„",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"status": "error", "message": str(e)}
    
    def _get_api_data(self, hours: int) -> List[Dict]:
        """API ë°ì´í„° ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cutoff_time = datetime.now() - timedelta(hours=hours)
            
            cursor.execute("""
                SELECT url, method, status_code, elapsed, created_at, test_case_id, serial
                FROM test_api 
                WHERE created_at > ?
                ORDER BY created_at ASC
            """, (cutoff_time.strftime('%Y-%m-%d %H:%M:%S'),))
            
            results = cursor.fetchall()
            conn.close()
            
            return [
                {
                    'url': row[0],
                    'method': row[1],
                    'status_code': row[2],
                    'elapsed': row[3],
                    'created_at': row[4],
                    'test_case_id': row[5],
                    'serial': row[6]
                }
                for row in results
            ]
            
        except Exception as e:
            logger.error(f"API ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _analyze_endpoint_frequency(self, api_data: List[Dict]) -> Dict:
        """ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ë¹ˆë„ ë¶„ì„"""
        endpoint_counter = Counter()
        endpoint_methods = defaultdict(set)
        
        for item in api_data:
            url = item.get('url', '')
            method = item.get('method', 'GET')
            
            # URL ì •ê·œí™” (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°)
            normalized_url = re.sub(r'\?.*$', '', url)
            endpoint_counter[normalized_url] += 1
            endpoint_methods[normalized_url].add(method)
        
        # ìƒìœ„ 10ê°œ ì—”ë“œí¬ì¸íŠ¸
        top_endpoints = endpoint_counter.most_common(10)
        
        return {
            "total_unique_endpoints": len(endpoint_counter),
            "top_endpoints": [
                {
                    "url": endpoint,
                    "count": count,
                    "percentage": (count / len(api_data)) * 100,
                    "methods": list(endpoint_methods[endpoint])
                }
                for endpoint, count in top_endpoints
            ],
            "endpoint_distribution": dict(endpoint_counter)
        }
    
    def _analyze_method_distribution(self, api_data: List[Dict]) -> Dict:
        """HTTP ë©”ì„œë“œ ë¶„í¬ ë¶„ì„"""
        method_counter = Counter()
        
        for item in api_data:
            method = item.get('method', 'GET')
            method_counter[method] += 1
        
        total_requests = len(api_data)
        
        return {
            "total_requests": total_requests,
            "method_distribution": [
                {
                    "method": method,
                    "count": count,
                    "percentage": (count / total_requests) * 100
                }
                for method, count in method_counter.most_common()
            ]
        }
    
    def _analyze_status_patterns(self, api_data: List[Dict]) -> Dict:
        """ìƒíƒœ ì½”ë“œ íŒ¨í„´ ë¶„ì„"""
        status_counter = Counter()
        status_by_endpoint = defaultdict(Counter)
        
        for item in api_data:
            status = item.get('status_code', 200)
            url = re.sub(r'\?.*$', '', item.get('url', ''))
            
            status_counter[status] += 1
            status_by_endpoint[url][status] += 1
        
        # ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„
        error_patterns = []
        for endpoint, statuses in status_by_endpoint.items():
            error_count = sum(count for status, count in statuses.items() if status >= 400)
            total_count = sum(statuses.values())
            error_rate = (error_count / total_count) * 100 if total_count > 0 else 0
            
            if error_rate > 5:  # 5% ì´ìƒ ì˜¤ë¥˜ìœ¨
                error_patterns.append({
                    "endpoint": endpoint,
                    "error_rate": error_rate,
                    "total_requests": total_count,
                    "error_requests": error_count,
                    "status_breakdown": dict(statuses)
                })
        
        return {
            "status_distribution": [
                {
                    "status_code": status,
                    "count": count,
                    "percentage": (count / len(api_data)) * 100
                }
                for status, count in status_counter.most_common()
            ],
            "error_patterns": sorted(error_patterns, key=lambda x: x['error_rate'], reverse=True)
        }
    
    def _analyze_timing_patterns(self, api_data: List[Dict]) -> Dict:
        """íƒ€ì´ë° íŒ¨í„´ ë¶„ì„"""
        timing_data = []
        
        for item in api_data:
            elapsed = item.get('elapsed')
            if elapsed:
                timing_data.append(float(elapsed))
        
        if not timing_data:
            return {"message": "íƒ€ì´ë° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        hourly_timing = defaultdict(list)
        for item in api_data:
            if item.get('elapsed'):
                created_at = datetime.fromisoformat(item['created_at'].replace('Z', '+00:00'))
                hour = created_at.hour
                hourly_timing[hour].append(float(item['elapsed']))
        
        hourly_stats = {}
        for hour, times in hourly_timing.items():
            hourly_stats[hour] = {
                "avg_response_time": sum(times) / len(times),
                "max_response_time": max(times),
                "min_response_time": min(times),
                "request_count": len(times)
            }
        
        return {
            "overall_timing": {
                "avg_response_time": sum(timing_data) / len(timing_data),
                "max_response_time": max(timing_data),
                "min_response_time": min(timing_data),
                "total_requests": len(timing_data)
            },
            "hourly_timing": dict(hourly_stats)
        }
    
    def _analyze_request_sequences(self, api_data: List[Dict]) -> Dict:
        """ìš”ì²­ ì‹œí€€ìŠ¤ íŒ¨í„´ ë¶„ì„"""
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ì‹œí€€ìŠ¤ ë¶„ì„
        test_sequences = defaultdict(list)
        
        for item in api_data:
            test_case_id = item.get('test_case_id')
            if test_case_id:
                url = re.sub(r'\?.*$', '', item.get('url', ''))
                test_sequences[test_case_id].append(url)
        
        # ê³µí†µ ì‹œí€€ìŠ¤ íŒ¨í„´ ì°¾ê¸°
        sequence_patterns = []
        for test_case_id, sequence in test_sequences.items():
            if len(sequence) >= 3:  # 3ê°œ ì´ìƒì˜ ìš”ì²­ì´ ìˆëŠ” ì‹œí€€ìŠ¤ë§Œ
                sequence_patterns.append({
                    "test_case_id": test_case_id,
                    "sequence": sequence,
                    "length": len(sequence)
                })
        
        # ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ì°¾ê¸°
        longest_sequence = max(sequence_patterns, key=lambda x: x['length']) if sequence_patterns else None
        
        return {
            "total_test_cases": len(test_sequences),
            "sequence_patterns": sequence_patterns,
            "longest_sequence": longest_sequence,
            "avg_sequence_length": sum(len(seq) for seq in test_sequences.values()) / len(test_sequences) if test_sequences else 0
        }
    
    def _detect_anomalies(self, api_data: List[Dict]) -> List[Dict]:
        """ì´ìƒ íŒ¨í„´ ê°ì§€"""
        anomalies = []
        
        # 1. ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ì‘ë‹µ ì‹œê°„
        response_times = [float(item.get('elapsed', 0)) for item in api_data if item.get('elapsed')]
        if response_times:
            avg_response_time = sum(response_times) / len(response_times)
            threshold = avg_response_time * 3  # í‰ê· ì˜ 3ë°°
            
            for item in api_data:
                if item.get('elapsed') and float(item['elapsed']) > threshold:
                    anomalies.append({
                        "type": "slow_response",
                        "severity": "high",
                        "message": f"ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ì‘ë‹µ ì‹œê°„: {item['elapsed']}ì´ˆ",
                        "url": item.get('url'),
                        "method": item.get('method'),
                        "value": float(item['elapsed']),
                        "threshold": threshold
                    })
        
        # 2. ë†’ì€ ì˜¤ë¥˜ìœ¨ ì—”ë“œí¬ì¸íŠ¸
        endpoint_errors = defaultdict(lambda: {"total": 0, "errors": 0})
        for item in api_data:
            url = re.sub(r'\?.*$', '', item.get('url', ''))
            endpoint_errors[url]["total"] += 1
            if item.get('status_code', 200) >= 400:
                endpoint_errors[url]["errors"] += 1
        
        for url, stats in endpoint_errors.items():
            error_rate = (stats["errors"] / stats["total"]) * 100
            if error_rate > 20:  # 20% ì´ìƒ ì˜¤ë¥˜ìœ¨
                anomalies.append({
                    "type": "high_error_rate",
                    "severity": "critical",
                    "message": f"ë†’ì€ ì˜¤ë¥˜ìœ¨ ì—”ë“œí¬ì¸íŠ¸: {error_rate:.1f}%",
                    "url": url,
                    "error_rate": error_rate,
                    "total_requests": stats["total"],
                    "error_requests": stats["errors"]
                })
        
        # 3. ë¹„ì •ìƒì ì¸ ìš”ì²­ ë¹ˆë„
        endpoint_frequency = Counter()
        for item in api_data:
            url = re.sub(r'\?.*$', '', item.get('url', ''))
            endpoint_frequency[url] += 1
        
        if endpoint_frequency:
            avg_frequency = sum(endpoint_frequency.values()) / len(endpoint_frequency)
            threshold = avg_frequency * 2  # í‰ê· ì˜ 2ë°°
            
            for url, count in endpoint_frequency.items():
                if count > threshold:
                    anomalies.append({
                        "type": "high_frequency",
                        "severity": "medium",
                        "message": f"ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ í˜¸ì¶œ ë¹ˆë„: {count}íšŒ",
                        "url": url,
                        "count": count,
                        "threshold": threshold
                    })
        
        return anomalies
    
    def generate_pattern_report(self) -> str:
        """íŒ¨í„´ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        analysis = self.analyze_api_patterns(24)  # 24ì‹œê°„ ë¶„ì„
        
        if analysis.get('status') != 'success':
            return f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {analysis.get('message', 'Unknown error')}"
        
        patterns = analysis['patterns']
        
        report = f"""
=== API íŒ¨í„´ ë¶„ì„ ë¦¬í¬íŠ¸ ===
ë¶„ì„ ê¸°ê°„: {analysis['analysis_period']}
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ë¹ˆë„ (ìƒìœ„ 5ê°œ):
"""
        
        if patterns.get('endpoint_frequency', {}).get('top_endpoints'):
            for endpoint in patterns['endpoint_frequency']['top_endpoints'][:5]:
                report += f"- {endpoint['url']}\n"
                report += f"  í˜¸ì¶œ ìˆ˜: {endpoint['count']}íšŒ ({endpoint['percentage']:.1f}%)\n"
                report += f"  ë©”ì„œë“œ: {', '.join(endpoint['methods'])}\n"
        else:
            report += "- ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        
        report += f"\nğŸ” HTTP ë©”ì„œë“œ ë¶„í¬:\n"
        method_dist = patterns.get('method_distribution')
        if isinstance(method_dist, dict) and 'method_distribution' in method_dist:
            method_list = method_dist['method_distribution']
        elif isinstance(method_dist, list):
            method_list = method_dist
        else:
            method_list = []

        if method_list:
            for method_info in method_list:
                if isinstance(method_info, dict):
                    report += f"- {method_info.get('method', 'Unknown')}: {method_info.get('count', 0)}íšŒ ({method_info.get('percentage', 0):.1f}%)\n"
        else:
            report += "- ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        
        # ì˜¤ë¥˜ íŒ¨í„´
        error_patterns = patterns.get('status_patterns', {}).get('error_patterns', [])
        if error_patterns:
            report += f"\nğŸš¨ ì˜¤ë¥˜ìœ¨ì´ ë†’ì€ ì—”ë“œí¬ì¸íŠ¸:\n"
            for error in error_patterns[:3]:
                report += f"- {error['endpoint']}: {error['error_rate']:.1f}% ({error['error_requests']}/{error['total_requests']})\n"
        
        # ì´ìƒ ê°ì§€
        anomalies = patterns.get('anomalies', [])
        if anomalies:
            report += f"\nâš ï¸ ê°ì§€ëœ ì´ìƒ íŒ¨í„´:\n"
            for anomaly in anomalies[:5]:
                severity_icon = "ğŸ”´" if anomaly.get('severity') == 'critical' else "ğŸŸ¡" if anomaly.get('severity') == 'high' else "ğŸŸ¢"
                report += f"{severity_icon} {anomaly.get('message', '')}\n"
        else:
            report += f"\nâœ… ì´ìƒ íŒ¨í„´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
        
        return report

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    analyzer = APIPatternAnalyzer()
    
    # íŒ¨í„´ ë¶„ì„
    analysis = analyzer.analyze_api_patterns(6)  # 6ì‹œê°„ ë¶„ì„
    
    print("=== API íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ===")
    print(json.dumps(analysis, indent=2, ensure_ascii=False))
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report = analyzer.generate_pattern_report()
    print("\n" + report)

if __name__ == "__main__":
    main() 